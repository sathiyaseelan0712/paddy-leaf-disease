{"cells":[{"cell_type":"code","source":["!python --version"],"metadata":{"id":"XhmfnPsY0gZ1","executionInfo":{"status":"ok","timestamp":1756487640529,"user_tz":-330,"elapsed":128,"user":{"displayName":"SATHIYASEELAN S 22ADR096","userId":"01428932172222237066"}},"outputId":"0a06cc8a-faad-40fe-9498-d825d19711c5","colab":{"base_uri":"https://localhost:8080/"}},"id":"XhmfnPsY0gZ1","execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Python 3.12.11\n"]}]},{"cell_type":"code","execution_count":null,"id":"a9990e75-8490-4a7e-8d05-1d9db868e964","metadata":{"id":"a9990e75-8490-4a7e-8d05-1d9db868e964","outputId":"cdea470a-2de4-4ea5-fe0a-1326c2cfd384"},"outputs":[{"name":"stderr","output_type":"stream","text":["WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"name":"stdout","output_type":"stream","text":["Loaded resnet50 model successfully\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"name":"stdout","output_type":"stream","text":["Loaded vgg16 model successfully\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"name":"stdout","output_type":"stream","text":["Loaded inceptionv3 model successfully\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"name":"stdout","output_type":"stream","text":["Loaded xception model successfully\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n","Warmed up resnet50 model\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step   \n","Warmed up vgg16 model\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8s/step\n","Warmed up inceptionv3 model\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n","Warmed up xception model\n","Generating explainable AI visualizations for all models...\n","Output directory: output/multi_model_explainable_ai_20250829_160537\n","\n","================================================================================\n","MODEL PREDICTIONS:\n","================================================================================\n","Processing resnet50...\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step\n","RESNET50       : Sheath Blight                  (99.44%)\n","Processing vgg16...\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n","VGG16          : Brown Spot                     (78.58%)\n","Processing inceptionv3...\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step\n","INCEPTIONV3    : Brown Spot                     (85.56%)\n","Processing xception...\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step\n","XCEPTION       : Leaf scald                     (54.16%)\n","================================================================================\n","\n","MODEL AGREEMENT SUMMARY:\n","================================================================================\n","RESNET50 and VGG16     : DISAGREE (Sheath Blight vs Brown Spot)\n","RESNET50 and INCEPTIONV3: DISAGREE (Sheath Blight vs Brown Spot)\n","RESNET50 and XCEPTION  : DISAGREE (Sheath Blight vs Leaf scald)\n","VGG16 and INCEPTIONV3: AGREE on Brown Spot\n","VGG16 and XCEPTION  : DISAGREE (Brown Spot vs Leaf scald)\n","INCEPTIONV3 and XCEPTION  : DISAGREE (Brown Spot vs Leaf scald)\n","================================================================================\n","\n","FINAL DETERMINATION:\n","================================================================================\n","✗ This is NOT a paddy leaf\n","  Not enough model agreement to identify a paddy leaf disease\n","================================================================================\n","\n","Multi-model explainable AI analysis complete!\n","All visualizations saved in: output/multi_model_explainable_ai_20250829_160537\n","\n","Generated multi-model explainable AI images in: output/multi_model_explainable_ai_20250829_160537\n","\n","Key Files Created:\n","📊 multi_model_comparison.png - Side-by-side model comparisons\n","📈 confidence_comparison.png - Confidence scores across classes\n","🤝 agreement_matrix.png - Model agreement visualization\n","📋 multi_model_summary.json - JSON summary of all results\n","🔍 resnet50_explanation.png - Individual resnet50 explanation\n","🔍 vgg16_explanation.png - Individual vgg16 explanation\n","🔍 inceptionv3_explanation.png - Individual inceptionv3 explanation\n","🔍 xception_explanation.png - Individual xception explanation\n","📄 multi_model_analysis_report.txt - Detailed analysis report\n"]}],"source":["import numpy as np\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","import cv2\n","import os\n","import json\n","from collections import Counter\n","from tensorflow.keras.models import load_model\n","from tensorflow.keras.preprocessing import image\n","from datetime import datetime\n","\n","# -------------------------\n","# All Available Models\n","# -------------------------\n","MODEL_NAMES = [\"resnet50\", \"vgg16\", \"inceptionv3\", \"xception\"]\n","MODEL_PATHS = {\n","    \"resnet50\": f\"/home/22adr096/resnet50_model.h5\",\n","    \"vgg16\": f\"/home/22adr096/vgg16_model.h5\",\n","    \"inceptionv3\": f\"/home/22adr096/inceptionv3_model.h5\",\n","    \"xception\": f\"/home/22adr096/xception_model.h5\"\n","}\n","\n","# -------------------------\n","# Load all saved models\n","# -------------------------\n","models = {}\n","for model_name in MODEL_NAMES:\n","    try:\n","        models[model_name] = load_model(MODEL_PATHS[model_name])\n","        print(f\"Loaded {model_name} model successfully\")\n","    except Exception as e:\n","        print(f\"Failed to load {model_name} model: {e}\")\n","\n","# Check if any models were loaded\n","if not models:\n","    raise ValueError(\"No models were loaded successfully. Please check model paths.\")\n","\n","# -------------------------\n","# Model configuration\n","# -------------------------\n","MODEL_CONFIGS = {\n","    \"resnet50\": {\n","        \"input_size\": (224, 224),\n","        \"preprocess_func\": tf.keras.applications.resnet50.preprocess_input\n","    },\n","    \"vgg16\": {\n","        \"input_size\": (224, 224),\n","        \"preprocess_func\": tf.keras.applications.vgg16.preprocess_input\n","    },\n","    \"inceptionv3\": {\n","        \"input_size\": (299, 299),\n","        \"preprocess_func\": tf.keras.applications.inception_v3.preprocess_input\n","    },\n","    \"xception\": {\n","        \"input_size\": (299, 299),\n","        \"preprocess_func\": tf.keras.applications.xception.preprocess_input\n","    }\n","}\n","\n","# Warm-up calls for all models\n","for model_name, model in models.items():\n","    input_size = MODEL_CONFIGS[model_name][\"input_size\"]\n","    _dummy = np.zeros((1, input_size[0], input_size[1], 3), dtype=np.float32)\n","    _ = model.predict(_dummy)\n","    print(f\"Warmed up {model_name} model\")\n","\n","# -------------------------\n","# Class labels\n","# -------------------------\n","class_labels = ['Bacterial Leaf Blight', 'Brown Spot', 'Healthy Rice Leaf',\n","                'Leaf Blast', 'Leaf scald', 'Narrow Brown Leaf Spot',\n","                'Neck_Blast', 'Rice Hispa', 'Sheath Blight']\n","\n","# -------------------------\n","# Preprocessing function\n","# -------------------------\n","def preprocess_image(img_path, model_name):\n","    input_size = MODEL_CONFIGS[model_name][\"input_size\"]\n","\n","    original_img = cv2.imread(img_path)\n","    original_img = cv2.cvtColor(original_img, cv2.COLOR_BGR2RGB)\n","\n","    img = image.load_img(img_path, target_size=input_size)\n","    img_array = image.img_to_array(img)\n","    img_array = np.expand_dims(img_array, axis=0)\n","\n","    img_tensor = tf.convert_to_tensor(img_array, dtype=tf.float32)\n","    preprocess_func = MODEL_CONFIGS[model_name][\"preprocess_func\"]\n","    img_preprocessed = preprocess_func(img_tensor)\n","\n","    return original_img, img_tensor, img_preprocessed\n","\n","# -------------------------\n","# Utilities\n","# -------------------------\n","def create_output_directory():\n","    \"\"\"Create output directory inside 'output/' with timestamp\"\"\"\n","    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n","    base_dir = \"output\"\n","    output_dir = os.path.join(base_dir, f\"multi_model_explainable_ai_{timestamp}\")\n","    os.makedirs(output_dir, exist_ok=True)\n","    return output_dir\n","\n","# -------------------------\n","# Explanation Generation Functions\n","# -------------------------\n","def generate_gradient_explanation(img_tensor, model, class_index=None):\n","    \"\"\"Generate gradient-based explanation that always works\"\"\"\n","    with tf.GradientTape() as tape:\n","        tape.watch(img_tensor)\n","        predictions = model(img_tensor)\n","        if class_index is None:\n","            class_index = tf.argmax(predictions[0])\n","        class_output = predictions[:, class_index]\n","\n","    # Get gradients\n","    gradients = tape.gradient(class_output, img_tensor)\n","\n","    # Process gradients for visualization\n","    gradients = tf.abs(gradients)  # Take absolute value\n","    gradients = tf.reduce_mean(gradients, axis=-1)  # Average across channels\n","    gradients = gradients[0]  # Remove batch dimension\n","\n","    # Normalize to 0-1\n","    gradients = (gradients - tf.reduce_min(gradients)) / (tf.reduce_max(gradients) - tf.reduce_min(gradients))\n","\n","    return gradients.numpy()\n","\n","def generate_smoothgrad_explanation(img_tensor, model, class_index=None, noise_level=0.1, n_samples=50):\n","    \"\"\"Generate SmoothGrad explanation - reduces noise in gradients\"\"\"\n","    gradients_sum = tf.zeros_like(img_tensor)\n","\n","    for _ in range(n_samples):\n","        # Add random noise\n","        noise = tf.random.normal(tf.shape(img_tensor)) * noise_level\n","        noisy_img = img_tensor + noise\n","\n","        with tf.GradientTape() as tape:\n","            tape.watch(noisy_img)\n","            predictions = model(noisy_img)\n","            if class_index is None:\n","                class_index = tf.argmax(predictions[0])\n","            class_output = predictions[:, class_index]\n","\n","        gradients = tape.gradient(class_output, noisy_img)\n","        gradients_sum += gradients\n","\n","    # Average the gradients\n","    smooth_gradients = gradients_sum / n_samples\n","\n","    # Process for visualization\n","    smooth_gradients = tf.abs(smooth_gradients)\n","    smooth_gradients = tf.reduce_mean(smooth_gradients, axis=-1)\n","    smooth_gradients = smooth_gradients[0]\n","\n","    # Normalize\n","    smooth_gradients = (smooth_gradients - tf.reduce_min(smooth_gradients)) / \\\n","                      (tf.reduce_max(smooth_gradients) - tf.reduce_min(smooth_gradients))\n","\n","    return smooth_gradients.numpy()\n","\n","# -------------------------\n","# Visualization Functions\n","# -------------------------\n","def create_heatmap_overlay(original_img, heatmap, colormap=cv2.COLORMAP_JET, alpha=0.4):\n","    \"\"\"Create heatmap overlay on original image\"\"\"\n","    # Resize heatmap to match original image\n","    heatmap_resized = cv2.resize(heatmap, (original_img.shape[1], original_img.shape[0]))\n","\n","    # Convert to 0-255 range\n","    heatmap_uint8 = np.uint8(255 * heatmap_resized)\n","\n","    # Apply colormap\n","    heatmap_colored = cv2.applyColorMap(heatmap_uint8, colormap)\n","    heatmap_colored = cv2.cvtColor(heatmap_colored, cv2.COLOR_BGR2RGB)\n","\n","    # Create overlay\n","    overlay = cv2.addWeighted(original_img, 1-alpha, heatmap_colored, alpha, 0)\n","    return overlay, heatmap_colored\n","\n","def save_model_explanation(original_img, explanation, model_name, pred_class, confidence, filename, output_dir):\n","    \"\"\"Save explanation for a single model\"\"\"\n","    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n","\n","    # Original image\n","    axes[0].imshow(original_img)\n","    axes[0].set_title(\"Original Image\")\n","    axes[0].axis('off')\n","\n","    # Explanation heatmap\n","    axes[1].imshow(explanation, cmap='hot')\n","    axes[1].set_title(f\"{model_name} Heatmap\")\n","    axes[1].axis('off')\n","\n","    # Overlay\n","    overlay, _ = create_heatmap_overlay(original_img, explanation, cv2.COLORMAP_JET)\n","    axes[2].imshow(overlay)\n","    axes[2].set_title(f\"{model_name} Overlay\")\n","    axes[2].axis('off')\n","\n","    plt.suptitle(f\"{model_name}: {class_labels[pred_class]} ({confidence:.1f}%)\", fontsize=16)\n","    plt.tight_layout()\n","    plt.savefig(os.path.join(output_dir, filename), dpi=300, bbox_inches='tight')\n","    plt.close()\n","\n","# -------------------------\n","# Paddy Leaf Detection Logic\n","# -------------------------\n","def is_paddy_leaf(predictions_dict, class_labels):\n","    \"\"\"\n","    Determine if the image is a paddy leaf based on model agreement.\n","    Returns: (is_paddy_leaf, final_prediction, confidence)\n","    \"\"\"\n","    # Count how many models predicted each class\n","    class_counts = Counter()\n","    model_predictions = {}\n","\n","    for model_name, data in predictions_dict.items():\n","        pred_class = data[\"pred_class\"]\n","        class_counts[pred_class] += 1\n","        model_predictions[model_name] = {\n","            \"class\": class_labels[pred_class],\n","            \"confidence\": data[\"confidence\"]\n","        }\n","\n","    # Find the most common prediction\n","    most_common = class_counts.most_common(1)\n","    if most_common:\n","        most_common_class, count = most_common[0]\n","\n","        # Check if at least 3 models agree\n","        if count >= 3:\n","            # Find the model with highest confidence for this class\n","            best_model = None\n","            best_confidence = 0\n","\n","            for model_name, data in predictions_dict.items():\n","                if data[\"pred_class\"] == most_common_class and data[\"confidence\"] > best_confidence:\n","                    best_confidence = data[\"confidence\"]\n","                    best_model = model_name\n","\n","            return True, class_labels[most_common_class], best_confidence, best_model\n","        else:\n","            # Not enough agreement - not a paddy leaf\n","            return False, \"Not a paddy leaf\", 0, None\n","    else:\n","        return False, \"Not a paddy leaf\", 0, None\n","\n","# -------------------------\n","# Custom JSON Encoder for NumPy types\n","# -------------------------\n","class NumpyEncoder(json.JSONEncoder):\n","    def default(self, obj):\n","        if isinstance(obj, np.integer):\n","            return int(obj)\n","        if isinstance(obj, np.floating):\n","            return float(obj)\n","        if isinstance(obj, np.ndarray):\n","            return obj.tolist()\n","        if isinstance(obj, np.bool_):\n","            return bool(obj)\n","        return super(NumpyEncoder, self).default(obj)\n","\n","# -------------------------\n","# Main Multi-Model Explainable AI Function\n","# -------------------------\n","def generate_multi_model_explanations(img_path, models, class_labels, output_dir=None):\n","    \"\"\"\n","    Generate explainable AI visualizations for all models and save as images\n","    \"\"\"\n","    if output_dir is None:\n","        output_dir = create_output_directory()\n","\n","    print(f\"Generating explainable AI visualizations for all models...\")\n","    print(f\"Output directory: {output_dir}\")\n","\n","    try:\n","        # Create a summary figure comparing all models\n","        n_models = len(models)\n","        fig, axes = plt.subplots(n_models, 4, figsize=(20, 5 * n_models))\n","\n","        if n_models == 1:\n","            axes = axes.reshape(1, -1)  # Ensure 2D array even for single model\n","\n","        analysis_data = {}\n","\n","        # Print header for predictions\n","        print(\"\\n\" + \"=\"*80)\n","        print(\"MODEL PREDICTIONS:\")\n","        print(\"=\"*80)\n","\n","        for i, (model_name, model) in enumerate(models.items()):\n","            print(f\"Processing {model_name}...\")\n","\n","            # Preprocess image for this specific model\n","            original_img, img_tensor, img_preprocessed = preprocess_image(img_path, model_name)\n","\n","            # Get predictions\n","            predictions = model.predict(img_preprocessed)\n","            pred_class = np.argmax(predictions[0])\n","            confidence = predictions[0][pred_class] * 100\n","\n","            # Print prediction to terminal\n","            print(f\"{model_name.upper():<15}: {class_labels[pred_class]:<30} ({confidence:.2f}%)\")\n","\n","            # Store analysis data\n","            analysis_data[model_name] = {\n","                \"pred_class\": pred_class,\n","                \"confidence\": confidence,\n","                \"predictions\": predictions[0]\n","            }\n","\n","            # Generate explanation\n","            explanation = generate_smoothgrad_explanation(img_preprocessed, model, pred_class, n_samples=30)\n","\n","            # Save individual model explanation\n","            save_model_explanation(\n","                original_img, explanation, model_name, pred_class, confidence,\n","                f\"{model_name}_explanation.png\", output_dir\n","            )\n","\n","            # Add to summary figure\n","            # Original image (only once)\n","            if i == 0:\n","                axes[i, 0].imshow(original_img)\n","                axes[i, 0].set_title(\"Original Image\")\n","            else:\n","                axes[i, 0].axis('off')\n","\n","            # Heatmap\n","            axes[i, 1].imshow(explanation, cmap='hot')\n","            axes[i, 1].set_title(f\"{model_name} Heatmap\")\n","            axes[i, 1].axis('off')\n","\n","            # Overlay\n","            overlay, _ = create_heatmap_overlay(original_img, explanation, cv2.COLORMAP_JET)\n","            axes[i, 2].imshow(overlay)\n","            axes[i, 2].set_title(f\"{model_name} Overlay\")\n","            axes[i, 2].axis('off')\n","\n","            # Prediction text\n","            axes[i, 3].text(0.1, 0.5,\n","                           f\"Model: {model_name}\\n\"\n","                           f\"Prediction: {class_labels[pred_class]}\\n\"\n","                           f\"Confidence: {confidence:.1f}%\",\n","                           fontsize=12, va='center')\n","            axes[i, 3].axis('off')\n","\n","        print(\"=\"*80)\n","\n","        plt.suptitle(f\"Multi-Model Explainable AI Analysis\", fontsize=20)\n","        plt.tight_layout()\n","        plt.savefig(os.path.join(output_dir, 'multi_model_comparison.png'), dpi=300, bbox_inches='tight')\n","        plt.close()\n","\n","        # Create prediction confidence comparison\n","        plt.figure(figsize=(12, 8))\n","        x_pos = np.arange(len(class_labels))\n","        colors = plt.cm.Set3(np.linspace(0, 1, len(models)))\n","\n","        for j, (model_name, data) in enumerate(analysis_data.items()):\n","            plt.plot(x_pos, data[\"predictions\"] * 100, 'o-', color=colors[j],\n","                    label=model_name, linewidth=2, markersize=8)\n","\n","        plt.xlabel('Class Labels')\n","        plt.ylabel('Confidence (%)')\n","        plt.title('Model Confidence Comparison Across Classes')\n","        plt.xticks(x_pos, class_labels, rotation=45, ha='right')\n","        plt.legend()\n","        plt.grid(True, alpha=0.3)\n","        plt.tight_layout()\n","        plt.savefig(os.path.join(output_dir, 'confidence_comparison.png'), dpi=300, bbox_inches='tight')\n","        plt.close()\n","\n","        # Create agreement matrix\n","        agreement_matrix = np.zeros((len(models), len(models)))\n","        model_names_list = list(models.keys())\n","\n","        for i, model1 in enumerate(model_names_list):\n","            for j, model2 in enumerate(model_names_list):\n","                if i == j:\n","                    agreement_matrix[i, j] = 1.0  # Same model always agrees\n","                else:\n","                    # Calculate agreement based on prediction similarity\n","                    pred1 = analysis_data[model1][\"pred_class\"]\n","                    pred2 = analysis_data[model2][\"pred_class\"]\n","                    conf1 = analysis_data[model1][\"confidence\"]\n","                    conf2 = analysis_data[model2][\"confidence\"]\n","\n","                    if pred1 == pred2:\n","                        # Models agree on class, weight by average confidence\n","                        agreement_matrix[i, j] = (conf1 + conf2) / 200\n","                    else:\n","                        # Models disagree\n","                        agreement_matrix[i, j] = 0\n","\n","        # Print agreement summary to terminal\n","        print(\"\\nMODEL AGREEMENT SUMMARY:\")\n","        print(\"=\"*80)\n","        for i, model1 in enumerate(model_names_list):\n","            for j, model2 in enumerate(model_names_list):\n","                if i < j:  # Only show each pair once\n","                    pred1 = analysis_data[model1][\"pred_class\"]\n","                    pred2 = analysis_data[model2][\"pred_class\"]\n","\n","                    if pred1 == pred2:\n","                        print(f\"{model1.upper()} and {model2.upper():<10}: AGREE on {class_labels[pred1]}\")\n","                    else:\n","                        print(f\"{model1.upper()} and {model2.upper():<10}: DISAGREE ({class_labels[pred1]} vs {class_labels[pred2]})\")\n","        print(\"=\"*80)\n","\n","        # Determine if it's a paddy leaf\n","        is_paddy, final_prediction, final_confidence, best_model = is_paddy_leaf(analysis_data, class_labels)\n","\n","        # Print final determination\n","        print(\"\\nFINAL DETERMINATION:\")\n","        print(\"=\"*80)\n","        if is_paddy:\n","            print(f\"✓ This is a paddy leaf with {final_prediction}\")\n","            print(f\"  Highest confidence: {final_confidence:.2f}% from {best_model}\")\n","        else:\n","            print(f\"✗ This is NOT a paddy leaf\")\n","            print(f\"  Not enough model agreement to identify a paddy leaf disease\")\n","        print(\"=\"*80)\n","\n","        # Plot agreement matrix\n","        plt.figure(figsize=(10, 8))\n","        plt.imshow(agreement_matrix, cmap='RdYlGn', vmin=0, vmax=1)\n","        plt.colorbar(label='Agreement Score')\n","        plt.xticks(np.arange(len(model_names_list)), model_names_list, rotation=45)\n","        plt.yticks(np.arange(len(model_names_list)), model_names_list)\n","        plt.title('Model Agreement Matrix')\n","\n","        # Add text annotations\n","        for i in range(len(model_names_list)):\n","            for j in range(len(model_names_list)):\n","                plt.text(j, i, f'{agreement_matrix[i, j]:.2f}',\n","                        ha='center', va='center', color='black' if agreement_matrix[i, j] > 0.5 else 'black')\n","\n","        plt.tight_layout()\n","        plt.savefig(os.path.join(output_dir, 'agreement_matrix.png'), dpi=300, bbox_inches='tight')\n","        plt.close()\n","\n","        # Create JSON summary\n","        json_summary = {\n","            \"image_path\": img_path,\n","            \"analysis_date\": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n","            \"is_paddy_leaf\": bool(is_paddy),  # Convert numpy bool to Python bool\n","            \"final_prediction\": str(final_prediction),\n","            \"final_confidence\": float(final_confidence),\n","            \"best_model\": str(best_model) if best_model else None,\n","            \"model_predictions\": {},\n","            \"model_agreement\": {}\n","        }\n","\n","        # Add model predictions\n","        for model_name, data in analysis_data.items():\n","            json_summary[\"model_predictions\"][model_name] = {\n","                \"predicted_class\": str(class_labels[data[\"pred_class\"]]),\n","                \"confidence\": float(data[\"confidence\"]),\n","                \"all_predictions\": {str(class_labels[i]): float(prob * 100) for i, prob in enumerate(data[\"predictions\"])}\n","            }\n","\n","        # Add model agreement\n","        for i, model1 in enumerate(model_names_list):\n","            for j, model2 in enumerate(model_names_list):\n","                if i != j:\n","                    key = f\"{model1}_{model2}\"\n","                    pred1 = analysis_data[model1][\"pred_class\"]\n","                    pred2 = analysis_data[model2][\"pred_class\"]\n","                    json_summary[\"model_agreement\"][key] = {\n","                        \"agree\": bool(pred1 == pred2),  # Convert numpy bool to Python bool\n","                        \"class1\": str(class_labels[pred1]),\n","                        \"class2\": str(class_labels[pred2]),\n","                        \"agreement_score\": float(agreement_matrix[i, j])\n","                    }\n","\n","        # Save JSON summary with custom encoder\n","        with open(os.path.join(output_dir, 'multi_model_summary.json'), 'w') as f:\n","            json.dump(json_summary, f, indent=4, cls=NumpyEncoder)\n","\n","        # Create analysis report\n","        with open(os.path.join(output_dir, 'multi_model_analysis_report.txt'), 'w') as f:\n","            f.write(\"MULTI-MODEL EXPLAINABLE AI ANALYSIS REPORT\\n\")\n","            f.write(\"=\" * 60 + \"\\n\\n\")\n","            f.write(f\"Image: {img_path}\\n\")\n","            f.write(f\"Analysis Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\\n\")\n","\n","            f.write(\"FINAL DETERMINATION:\\n\")\n","            f.write(\"-\" * 30 + \"\\n\")\n","            if is_paddy:\n","                f.write(f\"This is a paddy leaf with {final_prediction}\\n\")\n","                f.write(f\"Highest confidence: {final_confidence:.2f}% from {best_model}\\n\")\n","            else:\n","                f.write(\"This is NOT a paddy leaf\\n\")\n","                f.write(\"Not enough model agreement to identify a paddy leaf disease\\n\")\n","\n","            f.write(\"\\nMODEL PREDICTIONS:\\n\")\n","            f.write(\"-\" * 30 + \"\\n\")\n","            for model_name, data in analysis_data.items():\n","                f.write(f\"{model_name}: {class_labels[data['pred_class']]} ({data['confidence']:.2f}%)\\n\")\n","\n","            f.write(\"\\nDETAILED PREDICTIONS:\\n\")\n","            f.write(\"-\" * 30 + \"\\n\")\n","            for model_name, data in analysis_data.items():\n","                f.write(f\"\\n{model_name}:\\n\")\n","                top_5_indices = np.argsort(data[\"predictions\"])[-5:][::-1]\n","                for idx in top_5_indices:\n","                    f.write(f\"  {class_labels[idx]}: {data['predictions'][idx]*100:.2f}%\\n\")\n","\n","            f.write(f\"\\nGenerated Files:\\n\")\n","            f.write(\"- multi_model_comparison.png - Side-by-side model comparisons\\n\")\n","            f.write(\"- confidence_comparison.png - Confidence scores across classes\\n\")\n","            f.write(\"- agreement_matrix.png - Model agreement visualization\\n\")\n","            f.write(\"- multi_model_summary.json - JSON summary of all results\\n\")\n","            for model_name in models.keys():\n","                f.write(f\"- {model_name}_explanation.png - Individual model explanation\\n\")\n","\n","        print(f\"\\nMulti-model explainable AI analysis complete!\")\n","        print(f\"All visualizations saved in: {output_dir}\")\n","\n","        return output_dir\n","\n","    except Exception as e:\n","        print(f\"Error during multi-model analysis: {e}\")\n","        import traceback\n","        traceback.print_exc()\n","\n","        return output_dir\n","\n","# -------------------------\n","# Usage\n","# -------------------------\n","if __name__ == \"__main__\":\n","    # Example usage\n","    img_path = \"/home/22adr096/apple_leaf.png\"  # Replace with your image path\n","\n","    # Generate explainable AI visualizations for all models\n","    output_directory = generate_multi_model_explanations(img_path, models, class_labels)\n","\n","    print(f\"\\nGenerated multi-model explainable AI images in: {output_directory}\")\n","    print(\"\\nKey Files Created:\")\n","    print(\"📊 multi_model_comparison.png - Side-by-side model comparisons\")\n","    print(\"📈 confidence_comparison.png - Confidence scores across classes\")\n","    print(\"🤝 agreement_matrix.png - Model agreement visualization\")\n","    print(\"📋 multi_model_summary.json - JSON summary of all results\")\n","    for model_name in models.keys():\n","        print(f\"🔍 {model_name}_explanation.png - Individual {model_name} explanation\")\n","    print(\"📄 multi_model_analysis_report.txt - Detailed analysis report\")"]},{"cell_type":"code","execution_count":null,"id":"2df81018-8595-4c91-b848-2dd64cdb8ada","metadata":{"id":"2df81018-8595-4c91-b848-2dd64cdb8ada"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.11"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}